{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8afa17cf-c4aa-4a5a-ab8a-e3a4a07a12e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful.\n"
     ]
    }
   ],
   "source": [
    "# Load dependencies\n",
    "# Data processing\n",
    "import pandas as pd\n",
    "\n",
    "# Parallel processing\n",
    "import swifter\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Misc\n",
    "import json # JSON manipulation\n",
    "import tldextract # Extract tlds\n",
    "import idna # Punycode conversions\n",
    "import re # Registry modifications\n",
    "from datetime import datetime # Date calculations\n",
    "\n",
    "# OUTPUT--------------\n",
    "\n",
    "print(\"Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84832669-9a1b-4f56-8416-6a6b674dc712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domains - nulls dropped: 0\n",
      "Domains - duplicates dropped: 99\n",
      "Whois - nulls dropped: 2650\n",
      "Whois - duplicates dropped: 198216\n",
      "Whois - nulls dropped: 147\n",
      "Successful.\n"
     ]
    }
   ],
   "source": [
    "# LOAD--------------------\n",
    "\n",
    "# icann.csv\n",
    "icann_df = pd.read_csv(\"data/icann.csv\")\n",
    "\n",
    "# Create tld-type dictionary\n",
    "tld_type = pd.Series(icann_df.type.values, index=icann_df.tld).to_dict()\n",
    "\n",
    "# registrar.csv\n",
    "registrar_df = pd.read_csv(\"data/registrar.csv\")\n",
    "\n",
    "# Create registrar-id dictionary\n",
    "registrar = pd.Series(registrar_df.registrar.values, index=registrar_df.id).to_dict()\n",
    "\n",
    "# LOAD--------------------\n",
    "\n",
    "# all_types_domain_balanced.json\n",
    "df = pd.read_json(\"data/all_types_domains_balanced.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# Print # of null entries\n",
    "before = len(df)\n",
    "df = df[df[\"domain\"].notnull()]\n",
    "after = len(df)\n",
    "print(f\"Domains - nulls dropped: {(before - after)}\")\n",
    "\n",
    "# Print # of duplicates\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[\"domain\"])\n",
    "after = len(df)\n",
    "print(f\"Domains - duplicates dropped: {(before - after)}\")\n",
    "\n",
    "# Print null entries\n",
    "# df = df[df[\"domain\"].isnull()]\n",
    "# print(null_entries)\n",
    "# df = df[df[\"domain\"].notnull()]\n",
    "\n",
    "# Print duplicates\n",
    "# duplicates = df[df.duplicated(subset=[\"domain\"], keep=False)]\n",
    "# print(duplicates)\n",
    "# df = df.drop_duplicates(subset=[\"domain\"])\n",
    "\n",
    "# LOAD--------------------\n",
    "\n",
    "# all_types_domains_balanced_registered_domains_whois_parsed.json\n",
    "# TODO: Uncomment duplicates after I figure out how to deal with them\n",
    "\n",
    "whois_df = pd.read_json(\"data/all_types_domains_balanced_registered_domains_whois_parsed_correct_registrar_names_deduplicated_ids.json\", orient=\"records\", lines=True)\n",
    "\n",
    "# Print # of null entries\n",
    "before = len(whois_df)\n",
    "whois_df = whois_df[whois_df[\"domain\"].notnull()]\n",
    "after = len(whois_df)\n",
    "print(f'Whois - nulls dropped: {(before - after)}')\n",
    "\n",
    "# Print # of duplicates\n",
    "before = len(whois_df)\n",
    "whois_df = whois_df.drop_duplicates(subset=[\"domain\"])\n",
    "after = len(whois_df)\n",
    "print(f'Whois - duplicates dropped: {(before - after)}')\n",
    "\n",
    "# Print # of malformed registrar ids\n",
    "before = len(whois_df)\n",
    "whois_df = whois_df[whois_df[\"registrar_id\"].notnull()]\n",
    "after = len(whois_df)\n",
    "print(f'Whois - nulls dropped: {(before - after)}')\n",
    "\n",
    "# Print null entries\n",
    "# null_entries = whois_df[whois_df[\"domain\"].isnull()]\n",
    "# print(null_entries)\n",
    "# whois_df = whois_df[whois_df[\"domain\"].notnull()]\n",
    "\n",
    "# Print duplicates\n",
    "# duplicates = whois_df[whois_df.duplicated(subset=[\"domain\"], keep=False)]\n",
    "# print(duplicates)\n",
    "# whois_df = whois_df.drop_duplicates(subset=[\"domain\"])\n",
    "\n",
    "\n",
    "# LOAD--------------------\n",
    "\n",
    "# tld-list-history-2023-11-01.json\n",
    "# Note: Don't need to drop the null entries or duplicates because there are no null entries and there are supposed to be duplicates \n",
    "tld_list_df = pd.read_csv(\"data/prices.csv\")\n",
    "\n",
    "# OUTPUT--------------\n",
    "\n",
    "print(\"Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fc0d60-337e-4a9c-814b-2b31fb505294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aca6aacbd7493c9e95798ed44fbce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/24429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80774fcabbc436d8141d3032555ad7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/24429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66097c507d745dab906c4fe97d6173d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/19686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1aefc7c8ab9453f93c2e6dae406e545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/19686 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67449b106e147728af966806b49b3a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/19603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806576a7c0eb414296ccca14c0715875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/4536493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful.\n"
     ]
    }
   ],
   "source": [
    "# Extract TLDs and get the TLD type on dataframes\n",
    "\n",
    "# APPLY--------------------\n",
    "\n",
    "# all_types_domain_balanced.json\n",
    "df[\"tld\"] = df[\"domain\"].swifter.apply(lambda x: tldextract.extract(x).suffix)\n",
    "df[\"tld_type\"] = df[\"tld\"].swifter.apply(lambda x: tld_type.get(x, 'unknown'))\n",
    "\n",
    "# APPLY--------------------\n",
    "\n",
    "# all_types_domains_balanced_registered_domains_whois_parsed.json\n",
    "# TLD Type\n",
    "whois_df[\"tld\"] = whois_df[\"domain\"].swifter.apply(lambda x: tldextract.extract(x).suffix)\n",
    "whois_df[\"tld_type\"] = whois_df[\"tld\"].swifter.apply(lambda x: tld_type.get(x, 'unknown'))\n",
    "\n",
    "# Registrar\n",
    "allowed_values = [9994, 9995, 9996, 9997, 9998, 9999, 10007, 10009, 4000001, 8888888]\n",
    "\n",
    "whois_df['registrar_id'] = whois_df['registrar_id'].astype(int)\n",
    "\n",
    "whois_df = whois_df[\n",
    "    (whois_df['registrar_id'].isin(allowed_values)) |\n",
    "    ((whois_df['registrar_id'] >= 57) & (whois_df['registrar_id'] <= 4325))\n",
    "]\n",
    "\n",
    "whois_df[\"registrar\"] = whois_df[\"registrar_id\"].swifter.apply(lambda x: registrar.get(x, 'unknown'))\n",
    "\n",
    "# APPLY--------------------\n",
    "\n",
    "# Convert to punycode\n",
    "# tld-list-history-2023-11-01.json\n",
    "tld_list_df['tld'] = tld_list_df['tld'].swifter.apply(lambda x: idna.encode(x).decode('utf-8') if any(ord(char) > 127 for char in x) else x)\n",
    "tld_list_df = tld_list_df.sort_values(by='tld', ascending=True)\n",
    "\n",
    "# OUTPUT--------------\n",
    "\n",
    "print(\"Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f842a1a8-13c8-4eab-b2fd-10830b534995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whois - null dates dropped: 699\n",
      "Whois - misconfigured dates dropped: 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184ef9e5751c45d298dc8d4b71f6d2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/18792 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15ae8ca38d34ed6b68288ac3617a53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/18792 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful.\n"
     ]
    }
   ],
   "source": [
    "# Set up to add price data to whois_df from tld_list_df\n",
    "# TODO: figure out how to determine whether to use renewal, register, or transfer price\n",
    "# Note: I made copies since the not null dates still provides some useful info for malicious popularity\n",
    "\n",
    "### FORMAT---------------------\n",
    "\n",
    "# Drop null dates\n",
    "before = len(whois_df)\n",
    "whois_price = whois_df[whois_df[\"created\"].notnull()].copy()\n",
    "after = len(whois_price)\n",
    "print(f\"Whois - null dates dropped: {(before - after)}\")\n",
    "\n",
    "# No null tld_list dates\n",
    "tld_list_price = tld_list_df[tld_list_df[\"date\"].notnull()].copy()\n",
    "\n",
    "# Format dates\n",
    "whois_price[\"created\"] = pd.to_datetime(whois_price[\"created\"], format=\"%Y-%m-%d\", errors='coerce')\n",
    "tld_list_price[\"date\"] = pd.to_datetime(tld_list_price[\"date\"], format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "# Drop misconfigured dates\n",
    "before = len(whois_price)\n",
    "whois_price = whois_price[whois_price[\"created\"].notna()]\n",
    "after = len(whois_price)\n",
    "print(f'Whois - misconfigured dates dropped: {(before - after)}')\n",
    "\n",
    "# No miscofigured tld_list dates\n",
    "tld_list_price = tld_list_price[tld_list_price[\"date\"].notna()]\n",
    "\n",
    "### FILTER--------------------\n",
    "\n",
    "# Filter for only register prices\n",
    "tld_list_price = tld_list_price[tld_list_price[\"price-type\"] == \"register\"]\n",
    "\n",
    "# Group data by tld\n",
    "tld_list_price = tld_list_price.groupby(\"tld\")\n",
    "\n",
    "### FUNCTIONS--------------------\n",
    "\n",
    "# Function to find the price closest to the created date\n",
    "def find_closest_price(row):\n",
    "    try:\n",
    "        # Retrieve the tld group\n",
    "        tld_group = tld_list_price.get_group(row[\"tld\"])\n",
    "    except KeyError:\n",
    "        # If there is no group, return none\n",
    "        return pd.Series([None, None, None], index=[\"price\", \"price-date\", \"price-registrar\"])\n",
    "    \n",
    "    # Compute days difference and find the closest date\n",
    "    tld_group['days-difference'] = (row['created'] - tld_group['date']).dt.days\n",
    "    closest_date = tld_group[tld_group['days-difference'] >= 0].nsmallest(1, 'days-difference')\n",
    "    \n",
    "    # Check if closest_date is empty\n",
    "    if closest_date.empty:\n",
    "        return pd.Series([None, None, None], index=[\"price\", \"price-date\", \"price-registrar\"])\n",
    "\n",
    "    # Concatenate the registrars (sadly not working rn)\n",
    "    # registrars = ', '.join(set(closest_date['registrar']))\n",
    "    return pd.Series([closest_date[\"price\"].iloc[0], closest_date[\"date\"].dt.date.iloc[0], closest_date[\"registrar\"].iloc[0]], index=[\"price\", \"price-date\", \"price-registrar\"])\n",
    "\n",
    "# Function to split computation load among 10 cores\n",
    "def apply_parallel(data, func):\n",
    "    data_split = np.array_split(data, 10)\n",
    "    with Pool(processes=10) as pool:\n",
    "        data = pd.concat(pool.map(func, data_split))\n",
    "    return data\n",
    "\n",
    "# Function to run find_closest_price on each individualrow\n",
    "def process_chunk(chunk):\n",
    "    return chunk.apply(find_closest_price, axis=1)\n",
    "\n",
    "# APPLY--------------------\n",
    "\n",
    "# Apply function to the data frame\n",
    "whois_price[[\"price\", \"price-date\", \"price-registrar\"]] = apply_parallel(whois_price, process_chunk)\n",
    "\n",
    "# FORMAT--------------------\n",
    "\n",
    "# Make the none null dates human readable\n",
    "whois_price[\"created\"] = whois_price[\"created\"].swifter.apply(lambda x: x.strftime(\"%Y-%m-%d\") if pd.notnull(x) else x)\n",
    "whois_price[\"price-date\"] = whois_price[\"price-date\"].swifter.apply(lambda x: x.strftime(\"%Y-%m-%d\") if pd.notnull(x) else x)\n",
    "\n",
    "# OUTPUT--------------\n",
    "\n",
    "# Save whois_data to whois-with-prices.json\n",
    "# whois_price.to_json(\"output/whois-with-prices.json\", orient=\"records\", lines=True)\n",
    "\n",
    "print(\"Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f042419-0a26-4f54-a579-936c746e15a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whois - misconfigured dates dropped: 0\n",
      "Created graph 1\n",
      "Created graph 2\n",
      "Created graph 3\n",
      "Created graph 4\n",
      "Successful.\n"
     ]
    }
   ],
   "source": [
    "# Graph time\n",
    "# Convert date columns to datetime format\n",
    "whois_price['created'] = pd.to_datetime(whois_price['created'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "whois_price['updated'] = pd.to_datetime(whois_price['updated'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "whois_price['expires'] = pd.to_datetime(whois_price['expires'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "whois_price['price-date'] = pd.to_datetime(whois_price['price-date'], format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "# Drop misconfigured dates\n",
    "before = len(whois_price)\n",
    "whois_price = whois_price.dropna(subset=['domain', 'created', 'expires'])\n",
    "after = len(whois_price)\n",
    "print(f'Whois - misconfigured dates dropped: {(before - after)}')\n",
    "\n",
    "output_dir = './graphs/whois/'\n",
    "\n",
    "# Distribution of Domain Prices\n",
    "# Price range\n",
    "price_range = (0, 10)\n",
    "bin_width = 0.1\n",
    "bins = int((price_range[1] - price_range[0]) / bin_width)\n",
    "\n",
    "# Graphing/plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(whois_price['price'], bins=bins, range=price_range, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Domain Prices')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(0, 11, 1))\n",
    "plt.savefig(f'{output_dir}distribution_of_domain_prices.pdf')\n",
    "plt.close()\n",
    "print(\"Created graph 1\")\n",
    "\n",
    "# Domains by Registrar (Top 20)\n",
    "plt.figure(figsize=(14, 10))\n",
    "whois_price['registrar'].value_counts().head(20).plot(kind='bar', color='lightgreen')\n",
    "plt.title('Number of Domains by Registrar (Top 20)')\n",
    "plt.xlabel('Registrar')\n",
    "plt.ylabel('Number of Domains')\n",
    "plt.xticks(rotation=90, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "\n",
    "plt.savefig(f'{output_dir}domains_by_registrar.pdf')\n",
    "plt.close()\n",
    "print(\"Created graph 2\")\n",
    "\n",
    "# Domains by TLD\n",
    "plt.figure(figsize=(10, 8))\n",
    "whois_price['tld'].value_counts().head(10).plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['gold', 'lightblue'])\n",
    "plt.title('Distribution of Domains by TLD')\n",
    "plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{output_dir}domains_by_tld.pdf')\n",
    "plt.close()\n",
    "print(\"Created graph 3\")\n",
    "\n",
    "# Mean price by TLD\n",
    "top_tlds = whois_price['tld'].value_counts().head(20).index\n",
    "\n",
    "mean_prices = whois_price[whois_price['tld'].isin(top_tlds)].groupby('tld')['price'].mean().loc[top_tlds]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mean_prices.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "plt.title('Mean Price by TLD')\n",
    "plt.xlabel('TLD')\n",
    "plt.ylabel('Mean Price')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{output_dir}mean_price_by_tld.pdf')\n",
    "plt.close()\n",
    "print(\"Created graph 4\")\n",
    "\n",
    "# Note that the graph below won't work since we are pulling the best price, not the actual price\n",
    "# # Price by Registrar\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# whois_price.groupby('registrar')['price'].mean().plot(kind='bar', color='lightcoral')\n",
    "# plt.title('Average Price of Domains by Registrar')\n",
    "# plt.xlabel('Registrar')\n",
    "# plt.ylabel('Average Price')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.savefig(f'{output_dir}price_by_registrar.pdf')\n",
    "# plt.close()\n",
    "# print(\"Created graph 4\")\n",
    "\n",
    "print(\"Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed204cab-7a68-4915-81e8-c5055a5b6926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List threat sources\n",
    "sources = ['apt', 'phishtank', 'spamhaus', 'threatfox']\n",
    "\n",
    "# Function to plot the graphs\n",
    "def plot_tld(df, tld_type, source):\n",
    "    # Filter by source\n",
    "    if source is not None:\n",
    "        filtered_df = df[df['source'] == source]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "\n",
    "    # Filter by TLD type\n",
    "    if tld_type != 'overall':\n",
    "        filtered_df = filtered_df[filtered_df['tld_type'] == tld_type]\n",
    "\n",
    "    # Get the top 10\n",
    "    top_10_df = filtered_df['tld'].value_counts(normalize=True).head(10)\n",
    "    top_10_df['Other'] = 1 - top_10_df.sum()\n",
    "\n",
    "    # Configure graph type\n",
    "    plt.figure(figsize=(10,8))\n",
    "    top_10_df.plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=plt.cm.tab20.colors[:len(top_10_df)])\n",
    "\n",
    "    # Configure graph file name and title\n",
    "    if source is not None:\n",
    "        title = f'Top 10 {tld_type.capitalize()} TLD Popularity for {source.capitalize()}'\n",
    "        fname = f'./graphs/{source}_{tld_type}_popularity.pdf'\n",
    "    else:\n",
    "        title = f'Top 10 {tld_type.capitalize()} TLD Popularity'\n",
    "        fname = f'./graphs/{source}_popularity.pdf'\n",
    "\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.ylabel('')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, format='pdf')\n",
    "    plt.clf()\n",
    "\n",
    "# Create overall graphs\n",
    "plot_tld(df, 'overall', None)\n",
    "plot_tld(df, 'generic', None)\n",
    "plot_tld(df, 'country-code', None)\n",
    "\n",
    "# Create source graphs (apt, phishtank, spamhaus, threatfox)\n",
    "for source in sources:\n",
    "    plot_tld(df, 'overall', source)\n",
    "    plot_tld(df, 'generic', source)\n",
    "    plot_tld(df, 'country-code', source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
